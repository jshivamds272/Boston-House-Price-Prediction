# Boston-House-Price-Prediction

# Regularization--


![lasso and ridge](https://user-images.githubusercontent.com/81983943/145536202-bd5dbf99-c686-4437-9fe9-f92647668d4e.jpg)

One of the major aspects of training your machine learning model is avoiding overfitting. The model will have a low accuracy if it is overfitting. This happens because your model is trying too hard to capture the noise in your training dataset. By noise we mean the data points that donâ€™t really represent the true properties of your data, but random chance. Learning such data points, makes your model more flexible, at the risk of overfitting.

This is a form of regression, that constrains/ regularizes or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model, so as to avoid the risk of overfitting.

# 1-L1(Lasso Regression)-->

![lasso](https://user-images.githubusercontent.com/81983943/145536395-3a22db78-cfa7-4d91-8cf4-1bef3e2c014c.png)

# 2-L2(Ridge Regression)-->

![ridge](https://user-images.githubusercontent.com/81983943/145536482-a1b9a260-105e-4705-aea2-385ed54bcd6e.png)
